# Flow-RTPO æ¨¡å‹å’Œæ•°æ®é›†é…ç½®æŒ‡å—

## ğŸ“‹ å®Œæ•´æ¨¡å‹å’Œæ•°æ®é›†æ¸…å•

### ğŸ¤– **æ¨¡å‹åˆ—è¡¨**

| æ¨¡å‹ç±»å‹ | ç”¨é€” | HuggingFace åç§° | æœ¬åœ°è·¯å¾„ï¼ˆuse_local=Trueï¼‰ | åŠ è½½æ–¹å¼ |
|---------|------|-----------------|------------------------|---------|
| **SD3** | ä¸»è¦æ‰©æ•£æ¨¡å‹ | `stabilityai/stable-diffusion-3.5-medium` | `stable-diffusion-3.5-medium` | `StableDiffusion3Pipeline.from_pretrained()` |
| **LLaVA** | è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ | `llava-hf/llava-v1.6-mistral-7b-hf` | `llava-v1.6-mistral-7b-hf` | `LlavaNextForConditionalGeneration.from_pretrained()` |
| **CLIP** | å›¾åƒ-æ–‡æœ¬ç›¸ä¼¼åº¦ | `openai/clip-vit-large-patch14-336` | `clip-vit-large-patch14-336` | `CLIPModel.from_pretrained()` |
| **SBERT** | è¯­ä¹‰ç›¸ä¼¼åº¦ | `sentence-transformers/all-MiniLM-L6-v2` | `all-MiniLM-L6-v2` | `SentenceTransformer()` |
| **GTR-T5** | æ–‡æœ¬åµŒå…¥ç¼–ç å™¨ | `sentence-transformers/gtr-t5-base` | `gtr-t5-base` | `AutoModel.from_pretrained().encoder` |
| **vec2text** | æ–‡æœ¬åæ¼”æ¨¡å‹ | `gtr-base` | `gtr-base` | `vec2text.load_pretrained_corrector()` + ç¯å¢ƒå˜é‡ |
| **Detoxify** | æ¯’æ€§æ£€æµ‹ | `original` | `detoxify-original` | `Detoxify()` + ç¯å¢ƒå˜é‡ | checkpoint + bert

### ğŸ“š **æ•°æ®é›†åˆ—è¡¨**

| æ•°æ®é›† | ç”¨é€” | HuggingFace åç§° | æœ¬åœ°è·¯å¾„ï¼ˆuse_local=Trueï¼‰ | åŠ è½½æ–¹å¼ |
|-------|------|-----------------|------------------------|---------|
| **Real Toxicity Prompts** | è®­ç»ƒæ•°æ®é›† | `allenai/real-toxicity-prompts` | `real-toxicity-prompts` | `load_dataset()` æˆ– JSONæ–‡ä»¶ |

---

## ğŸ—‚ï¸ **æœ¬åœ°ç›®å½•ç»“æ„**

### **åŸºç¡€è·¯å¾„é…ç½®**
```python
# åœ¨ config/flow_rtpo.py ä¸­é…ç½®
config.model_loading.local_base_path = "/mnt/data/group/zhaoliangjie/ICLR-work/"
config.model_loading.use_local = True
```

### **å®Œæ•´ç›®å½•ç»“æ„**
```
/mnt/data/group/zhaoliangjie/ICLR-work/
â”œâ”€â”€ stable-diffusion-3.5-medium/           # SD3 æ‰©æ•£æ¨¡å‹
â”‚   â”œâ”€â”€ model_index.json
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”‚   â””â”€â”€ scheduler_config.json
â”‚   â”œâ”€â”€ text_encoder/
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â””â”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ text_encoder_2/
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â””â”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ text_encoder_3/
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â””â”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ tokenizer/
â”‚   â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”‚   â””â”€â”€ vocab.json
â”‚   â”œâ”€â”€ tokenizer_2/
â”‚   â”œâ”€â”€ tokenizer_3/
â”‚   â”œâ”€â”€ transformer/
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors
â”‚   â””â”€â”€ vae/
â”‚       â”œâ”€â”€ config.json
â”‚       â””â”€â”€ diffusion_pytorch_model.safetensors
â”‚
â”œâ”€â”€ llava-v1.6-mistral-7b-hf/              # LLaVA è§†è§‰è¯­è¨€æ¨¡å‹
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ generation_config.json
â”‚   â”œâ”€â”€ preprocessor_config.json
â”‚   â”œâ”€â”€ pytorch_model-00001-of-00004.bin
â”‚   â”œâ”€â”€ pytorch_model-00002-of-00004.bin
â”‚   â”œâ”€â”€ pytorch_model-00003-of-00004.bin
â”‚   â”œâ”€â”€ pytorch_model-00004-of-00004.bin
â”‚   â”œâ”€â”€ pytorch_model.bin.index.json
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”œâ”€â”€ tokenizer.model
â”‚   â””â”€â”€ tokenizer_config.json
â”‚
â”œâ”€â”€ clip-vit-large-patch14-336/             # CLIP æ¨¡å‹
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ preprocessor_config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ vocab.json
â”‚
â”œâ”€â”€ all-MiniLM-L6-v2/                       # SBERT æ¨¡å‹
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ config_sentence_transformers.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ sentence_bert_config.json
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ vocab.txt
â”‚
â”œâ”€â”€ gtr-t5-base/                            # GTR-T5 ç¼–ç å™¨
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ spiece.model
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â””â”€â”€ tokenizer.json
â”‚
â”œâ”€â”€ gtr-base/                               # vec2text æ¨¡å‹ç¼“å­˜
â”‚   â”œâ”€â”€ models--ielabgroup--vec2text_gtr-base-st_corrector/
â”‚   â”‚   â”œâ”€â”€ blobs/
â”‚   â”‚   â”œâ”€â”€ refs/
â”‚   â”‚   â””â”€â”€ snapshots/
â”‚   â”‚       â””â”€â”€ [commit_hash]/
â”‚   â”‚           â”œâ”€â”€ config.json
â”‚   â”‚           â”œâ”€â”€ pytorch_model.bin
â”‚   â”‚           â”œâ”€â”€ tokenizer_config.json
â”‚   â”‚           â”œâ”€â”€ tokenizer.json
â”‚   â”‚           â””â”€â”€ vocab.json
â”‚   â””â”€â”€ models--ielabgroup--vec2text_gtr-base-st_inversion/
â”‚       â”œâ”€â”€ blobs/
â”‚       â”œâ”€â”€ refs/
â”‚       â””â”€â”€ snapshots/
â”‚           â””â”€â”€ [commit_hash]/
â”‚               â”œâ”€â”€ config.json
â”‚               â”œâ”€â”€ pytorch_model.bin
â”‚               â””â”€â”€ ...
â”‚
â”œâ”€â”€ detoxify-original/                      # Detoxify æ¨¡å‹ç¼“å­˜
â”‚   â”œâ”€â”€ hub/
â”‚   â”‚   â””â”€â”€ checkpoints/
â”‚   â”‚       â””â”€â”€ toxic_original-c1212f89.ckpt
â”‚   â””â”€â”€ huggingface_cache/
â”‚       â””â”€â”€ models--unitary--toxic-bert-base/
â”‚           â”œâ”€â”€ blobs/
â”‚           â”œâ”€â”€ refs/
â”‚           â””â”€â”€ snapshots/
â”‚               â””â”€â”€ [commit_hash]/
â”‚                   â”œâ”€â”€ config.json
â”‚                   â”œâ”€â”€ pytorch_model.bin
â”‚                   â””â”€â”€ ...
â”‚
â””â”€â”€ real-toxicity-prompts/                  # RTP æ•°æ®é›†
    â”œâ”€â”€ dataset_info.json
    â”œâ”€â”€ state.json
    â””â”€â”€ data/
        â””â”€â”€ train-00000-of-00001.parquet
    # æˆ–è€… JSON æ ¼å¼ï¼š
    # â””â”€â”€ data.json
```

---

## ğŸ”§ **æœ¬åœ°åŠ è½½æœºåˆ¶è¯¦è§£**

### **1. æ ‡å‡†HuggingFaceæ¨¡å‹åŠ è½½ï¼ˆSD3, LLaVA, CLIP, SBERT, GTRï¼‰**
```python
def _get_model_path(self, model_type: str, default_path: str) -> str:
    if self.use_local:
        # ä»é…ç½®è·å–æœ¬åœ°æ¨¡å‹åç§°
        local_name = self.local_models.get(model_type, default_path.split('/')[-1])
        # ç»„åˆåŸºç¡€è·¯å¾„å’Œæ¨¡å‹åç§°
        return os.path.join(self.local_base_path, local_name)
    else:
        return self.hf_models.get(model_type, default_path)

# ä½¿ç”¨æ–¹å¼
model = AutoModel.from_pretrained(model_path)
```

### **2. vec2text ç¯å¢ƒå˜é‡åŠ è½½**
```python
# è®¾ç½®ç¯å¢ƒå˜é‡æŒ‡å‘æœ¬åœ°ç¼“å­˜
if self.use_local:
    # ä»é…ç½®è·å–vec2textæœ¬åœ°è·¯å¾„
    # å®é™…å€¼ï¼š"/mnt/data/group/zhaoliangjie/ICLR-work/gtr-base"
    vec2text_local_path = self.local_models.get('vec2text', 'gtr-base')
    
    # å¦‚æœä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œåˆ™ä¸åŸºç¡€è·¯å¾„ç»„åˆ
    if not vec2text_local_path.startswith('/'):
        vec2text_local_path = os.path.join(self.local_base_path, vec2text_local_path)
    
    # è®¾ç½®HuggingFaceç¼“å­˜ç¯å¢ƒå˜é‡
    os.environ['HF_HOME'] = vec2text_local_path
    os.environ['HF_HUB_CACHE'] = vec2text_local_path
    os.environ['TRANSFORMERS_CACHE'] = vec2text_local_path

# ä½¿ç”¨æ ‡å‡†APIï¼ˆä¼šä»ç¯å¢ƒå˜é‡æŒ‡å®šçš„ç¼“å­˜åŠ è½½ï¼‰
self.vec2text_corrector = vec2text.load_pretrained_corrector('gtr-base')

# æ¢å¤ç¯å¢ƒå˜é‡ï¼ˆç¡®ä¿ä¸å½±å“å…¶ä»–æ¨¡å—ï¼‰
```

### **3. Detoxify åŒé‡ç¼“å­˜åŠ è½½**
```python
# PyTorch Hub ç¼“å­˜ï¼ˆå­˜å‚¨.ckptæ£€æŸ¥ç‚¹ï¼‰
torch_hub_base = "/mnt/data/group/zhaoliangjie/ICLR-work/detoxify-original"
os.environ['TORCH_HOME'] = torch_hub_base

# HuggingFace ç¼“å­˜ï¼ˆå­˜å‚¨BERTæ¨¡å‹ï¼‰
hf_cache_dir = "/mnt/data/group/zhaoliangjie/ICLR-work/detoxify-original/huggingface_cache"
os.environ['HF_HOME'] = hf_cache_dir
os.environ['TRANSFORMERS_CACHE'] = hf_cache_dir

# ä½¿ç”¨æ ‡å‡†API
self.detoxify = Detoxify('original', device=self.device)
```

### **4. RTPæ•°æ®é›†åŠ è½½**
```python
# æ–¹å¼1ï¼šHuggingFace datasetsæ ¼å¼
dataset = load_dataset(local_dataset_path, cache_dir=self.cache_dir)

# æ–¹å¼2ï¼šJSONæ–‡ä»¶æ ¼å¼
json_path = os.path.join(local_dataset_path, "data.json")
with open(json_path, 'r') as f:
    train_data = json.load(f)
```

---

## âš ï¸ **ç‰¹æ®Šæ³¨æ„äº‹é¡¹**

### **1. vec2text ç‰¹æ®Šå¤„ç†**
- `vec2text.load_pretrained_corrector()` åªæ¥å—æ¨¡å‹åç§°ï¼Œä¸æ¥å—è·¯å¾„
- é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ `HF_HOME`, `HF_HUB_CACHE`, `TRANSFORMERS_CACHE` é‡å®šå‘ç¼“å­˜
- éœ€è¦åŒ…å«ä¸¤ä¸ªæ¨¡å‹ï¼š`corrector` å’Œ `inversion`

### **2. Detoxify åŒé‡ç¼“å­˜**
- PyTorch Hub ç¼“å­˜ï¼šå­˜å‚¨ `.ckpt` æ£€æŸ¥ç‚¹æ–‡ä»¶
- HuggingFace ç¼“å­˜ï¼šå­˜å‚¨ BERT æ¨¡å‹æ–‡ä»¶
- éœ€è¦æ­£ç¡®è®¾ç½® `TORCH_HOME` å’Œ `HF_HOME` ç¯å¢ƒå˜é‡

### **3. æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥**
```bash
# æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -la /mnt/data/group/zhaoliangjie/ICLR-work/stable-diffusion-3.5-medium/model_index.json
ls -la /mnt/data/group/zhaoliangjie/ICLR-work/llava-v1.6-mistral-7b-hf/config.json
ls -la /mnt/data/group/zhaoliangjie/ICLR-work/detoxify-original/hub/checkpoints/toxic_original-c1212f89.ckpt
```

### **4. å›é€€æœºåˆ¶**
æ‰€æœ‰æ¨¡å‹éƒ½å®ç°äº†å›é€€æœºåˆ¶ï¼š
1. æœ¬åœ°è·¯å¾„ä¸å­˜åœ¨ â†’ å›é€€åˆ° HuggingFace
2. æœ¬åœ°åŠ è½½å¤±è´¥ â†’ å›é€€åˆ° HuggingFace
3. HuggingFace åŠ è½½å¤±è´¥ â†’ æŠ›å‡ºå¼‚å¸¸æˆ–ä½¿ç”¨ mock æ•°æ®

---

## ğŸš€ **å¿«é€Ÿéƒ¨ç½²æ£€æŸ¥æ¸…å•**

### **é…ç½®æ–‡ä»¶è®¾ç½®**
- [ ] `config.model_loading.use_local = True`
- [ ] `config.model_loading.local_base_path = "/mnt/data/group/zhaoliangjie/ICLR-work/"`
- [ ] æ‰€æœ‰ `config.model_loading.local_models.*` è·¯å¾„æ­£ç¡®

### **ç›®å½•ç»“æ„éªŒè¯**
- [ ] åŸºç¡€ç›®å½•å­˜åœ¨ï¼š`/mnt/data/group/zhaoliangjie/ICLR-work/`
- [ ] æ‰€æœ‰æ¨¡å‹å­ç›®å½•å­˜åœ¨ä¸”åŒ…å«å¿…è¦æ–‡ä»¶
- [ ] Detoxify æ£€æŸ¥ç‚¹å­˜åœ¨ï¼š`detoxify-original/hub/checkpoints/toxic_original-c1212f89.ckpt`
- [ ] vec2text ç¼“å­˜ç›®å½•ç»“æ„æ­£ç¡®

### **æƒé™æ£€æŸ¥**
- [ ] ç›®å½•è¯»å–æƒé™
- [ ] æ¨¡å‹æ–‡ä»¶è¯»å–æƒé™
- [ ] ç¯å¢ƒå˜é‡è®¾ç½®æƒé™

### **æµ‹è¯•éªŒè¯**
```python
# æµ‹è¯•å„æ¨¡å‹åŠ è½½
from flow_grpo.prompt_editor import PromptEditorPolicy
from flow_grpo.toxicity_rewards import ToxicityRewardSystem
from flow_grpo.rtp_dataset import RealToxicityPromptsDataset

# éªŒè¯æ¨¡å‹åŠ è½½
policy = PromptEditorPolicy(use_local=True, local_base_path="/mnt/data/group/zhaoliangjie/ICLR-work/")
reward_system = ToxicityRewardSystem(use_local=True, local_base_path="/mnt/data/group/zhaoliangjie/ICLR-work/")
dataset = RealToxicityPromptsDataset(use_local=True, local_base_path="/mnt/data/group/zhaoliangjie/ICLR-work/")
```

---

## ğŸ“ **æ•…éšœæ’é™¤**

### **å¸¸è§é—®é¢˜**
1. **æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨**ï¼šæ£€æŸ¥è·¯å¾„é…ç½®å’Œæ–‡ä»¶å®Œæ•´æ€§
2. **æƒé™ä¸è¶³**ï¼šç¡®ä¿è¯»å–æƒé™æ­£ç¡®è®¾ç½®
3. **ç¯å¢ƒå˜é‡å†²çª**ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç¨‹åºè®¾ç½®äº†ç›¸åŒç¯å¢ƒå˜é‡
4. **ç‰ˆæœ¬å…¼å®¹æ€§**ï¼šç¡®ä¿æœ¬åœ°æ¨¡å‹ç‰ˆæœ¬ä¸ä»£ç å…¼å®¹

### **è°ƒè¯•æ—¥å¿—**
å¯åŠ¨è®­ç»ƒæ—¶æ³¨æ„è§‚å¯Ÿä»¥ä¸‹æ—¥å¿—ï¼š
```
[VEC2TEXT] Using local cache directory: /mnt/data/group/zhaoliangjie/ICLR-work/gtr-base
[DETOXIFY INIT] Found checkpoint: /mnt/data/group/zhaoliangjie/ICLR-work/detoxify-original/hub/checkpoints/toxic_original-c1212f89.ckpt
[CLIP LOCAL] Successfully loaded CLIP model from local path
[LOCAL] Successfully loaded local dataset with XXX samples
```

è¿™ä¸ªé…ç½®æŒ‡å—æ¶µç›–äº† Flow-RTPO é¡¹ç›®æ‰€éœ€çš„æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®é›†çš„æœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆã€‚